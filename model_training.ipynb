{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score,roc_curve,f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "colors = [\"#89CFF0\", \"#FF69B4\", \"#FFD700\", \"#7B68EE\", \"#FF4500\",\n",
    "          \"#9370DB\", \"#32CD32\", \"#8A2BE2\", \"#FF6347\", \"#20B2AA\",\n",
    "          \"#FF69B4\", \"#00CED1\", \"#FF7F50\", \"#7FFF00\", \"#DA70D6\"]\n",
    "\n",
    "def evaluate_model (y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print(\"Accuracy of the model is: %.2f\"%(accuracy * 100) , \"%\")\n",
    "    print(\"Precision of the model is: %.2f\" %(precision * 100) , \"%\")\n",
    "    print(\"Recall of the model is: %.2f\" %(recall * 100) , \"%\")\n",
    "    print(\"AUC value of the model is: %.2f\" %(roc * 100) , \"%\")\n",
    "    print(\"F1 score of the model is: %.2f\" %(f1 * 100) , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Faza Ulfath\\Downloads\\Thyroid-Cancer-Prediction-ML-Application--master\\Thyroid_Diff.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hx Radiothreapy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Physical Examination'].value_counts() # one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Recurred\")[\"Physical Examination\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 35px; font-weight: bold;\">Exploratory Data Analysis(EDA)</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 5),dpi=500)\n",
    "\n",
    "ax.hist(df['Age'], bins = 25, edgecolor = 'black', alpha = 0.7, color = 'skyblue', density = True)\n",
    "\n",
    "df['Age'].plot(kind = 'kde', color = 'red', ax = ax)\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Count / Density')\n",
    "ax.set_title('Age Distribution Histogram with Density Curve')\n",
    "ax.legend(['Density Curve', 'Histogram'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stage'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Stage\"].value_counts().plot(kind = 'bar', color = colors, rot = 0)\n",
    "ax.set_xticklabels((df['Stage'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Cancer Stage', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Gender\"].value_counts().plot(kind = 'bar', color = colors, rot = 0)\n",
    "ax.set_xticklabels((df['Gender'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Gender', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Risk\"].value_counts().plot(kind = 'bar', color = colors, rot = 0)\n",
    "ax.set_xticklabels((df['Risk'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Risk', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Recurred\"].value_counts().plot(kind = 'bar', color = colors, rot = 0)\n",
    "ax.set_xticklabels((df['Recurred'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Recurrence', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Smoking\"].value_counts().plot(kind = 'bar', color = colors, rot = 0)\n",
    "ax.set_xticklabels((df['Smoking'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Does the patient smoke?', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 6))\n",
    "ax = df[\"Response\"].value_counts().plot(kind = 'bar', color = colors, rot = 90)\n",
    "ax.set_xticklabels((df['Response'].value_counts().index))\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(int(p.get_height()), (p.get_x() + 0.25, p.get_height() + 1), ha = 'center', va = 'bottom', color = 'black')\n",
    "    ax.tick_params(axis = 'both', labelsize = 15)\n",
    "plt.xlabel('Response', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20)\n",
    "plt.ylabel('Number of Occurrences', weight = \"bold\", color = \"#D71313\", fontsize = 14, labelpad = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Recurred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Stage', hue='Recurred', data=df, palette='bone')\n",
    "\n",
    "plt.title('Recurrence Count for Each Stage', fontsize=16, weight='bold')\n",
    "plt.xlabel('Stage', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Gender', hue='Recurred', data=df, palette='pink')\n",
    "\n",
    "plt.title('Recurrence Count for Each Gender', fontsize=16, weight='bold')\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Smoking', hue='Recurred', data=df, palette='icefire')\n",
    "\n",
    "plt.title('Recurrence Count for Smoking Status', fontsize=16, weight='bold')\n",
    "plt.xlabel('Smoker', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Hx Radiothreapy', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Radiotherapy history', fontsize=16, weight='bold')\n",
    "plt.xlabel('Radiotherapy', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Thyroid Function', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Thyroid Function', fontsize=16, weight='bold')\n",
    "plt.xlabel('Thyroid Function', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Risk', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Risk', fontsize=16, weight='bold')\n",
    "plt.xlabel('Risk', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Adenopathy', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Adenopathy', fontsize=16, weight='bold')\n",
    "plt.xlabel('Adenopathy', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Focality', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Focality', fontsize=16, weight='bold')\n",
    "plt.xlabel('Focality', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Physical Examination', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Examination', fontsize=16, weight='bold')\n",
    "plt.xlabel('Physical Examination Findings', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Pathology', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Pathology', fontsize=16, weight='bold')\n",
    "plt.xlabel('Pathology', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Response', hue='Recurred', data=df, palette='flare')\n",
    "\n",
    "plt.title('Recurrence Count for Adenopathy', fontsize=16, weight='bold')\n",
    "plt.xlabel('Adenopathy', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Recurred', title_fontsize='12', fontsize='10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming and Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=ColumnTransformer(transformers=[\n",
    "    ('oh',OneHotEncoder(sparse_output=False,drop='first'), ['Gender','Thyroid Function','Physical Examination','Adenopathy','Pathology']),\n",
    "    ('oe',OrdinalEncoder(categories=[['No','Yes'],['No','Yes'],['No','Yes'],['Uni-Focal','Multi-Focal'],\n",
    "                                     ['Low','Intermediate','High'],['T1a', 'T1b', 'T2', 'T3a', 'T3b', 'T4a', 'T4b'],\n",
    "                                     ['N0','N1a','N1b'],['M0','M1'],['I', 'II', 'IVB', 'III', 'IVA'],\n",
    "                                     ['Excellent', 'Indeterminate', 'Biochemical Incomplete','Structural Incomplete']]),\n",
    "                                     ['Smoking','Hx Smoking','Hx Radiothreapy','Focality','Risk','T','N','M','Stage','Response'])\n",
    "],\n",
    "                              remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Recurred\",axis=1)\n",
    "y = df['Recurred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = {\"No\": 0 , \"Yes\":1}\n",
    "y = df['Recurred'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_feature_names = transformer.get_feature_names_out(input_features=X.columns)\n",
    "print(transformed_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cols = ['Gender', 'Thyroid Function_Clinical Hypothyroidism',\n",
    " 'Thyroid Function_Euthyroid',\n",
    " 'Thyroid Function_Subclinical Hyperthyroidism',\n",
    " 'Thyroid Function_Subclinical Hypothyroidism',\n",
    " 'Physical Examination_Multinodular goiter',\n",
    " 'Physical Examination_Normal',\n",
    " 'Physical Examination_Single nodular goiter-left',\n",
    " 'Physical Examination_Single nodular goiter-right',\n",
    " 'Adenopathy_Extensive', 'Adenopathy_Left', 'Adenopathy_No',\n",
    " 'Adenopathy_Posterior', 'Adenopathy_Right',\n",
    " 'Pathology_Hurthel cell', 'Pathology_Micropapillary',\n",
    " 'Pathology_Papillary', 'Smoking', 'Hx Smoking',\n",
    " 'Hx Radiothreapy', 'Focality', 'Risk', 'T', 'N', 'M',\n",
    " 'Stage', 'Response', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transformed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(data=X_transformed,columns=transformed_cols)\n",
    "transformed_df['Recurred'] = y\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_transformed,y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,X_val,y_test,y_val = train_test_split(X_test,y_test,test_size=0.5,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 700, 1000]\n",
    "criterion = ['gini','entropy','log_loss']\n",
    "max_depth = [10,20,50,100]\n",
    "bootstrap=[True,False]\n",
    "grid = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, bootstrap=bootstrap) # creating dictionary to store the lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_RF = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, cv=5, scoring='recall_macro', error_score=0) # creating grid search object for xgb\n",
    "GC_RF_result = GC_RF.fit(X_val_scaled ,y_val) # fitting the grid search on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.set_params(**GC_RF_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)  # Use y_pred[:, 1] for the positive class probabilities\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RF Model ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clsfr = XGBClassifier() #creating a model with no parameters\n",
    "n_estimators = [100, 300, 500, 700,1000] # creating lists for different values of hyperparameters\n",
    "subsample = [0.3,0.5, 0.7, 1.0]\n",
    "max_depth = [2,4,6, 7, 9]\n",
    "grid = dict(n_estimators=n_estimators, subsample=subsample, max_depth=max_depth) # creating dictionary to store the lists\n",
    "grid_search = GridSearchCV(estimator=xgb_clsfr, param_grid=grid, n_jobs=-1, cv=10, scoring='roc_auc', error_score=0) # creating grid search object for xgb\n",
    "grid_result = grid_search.fit(X_val_scaled, y_val) # fitting the grid search on the training data\n",
    "print(\"Highest ROC AUC is achieved using the parameters : \" , ( grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clsfr.set_params(**grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clsfr.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = xgb_clsfr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_cls = Sequential([\n",
    "    Dense(20, activation='relu', name='L1', kernel_regularizer=regularizers.l2(0.02)),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu', name='L2', kernel_regularizer=regularizers.l2(0.02)),\n",
    "    Dropout(0.1),\n",
    "    Dense(5, activation='relu', name='L3', kernel_regularizer=regularizers.l2(0.02)),\n",
    "    Dropout(0.1),\n",
    "    Dense(2, activation='linear', name='L4')\n",
    "])\n",
    "\n",
    "NN_cls.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_bal = NN_cls.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=150, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=NN_cls.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(NN_cls.predict(X_test_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "avg = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_transformed = transformer.fit_transform(X_train)\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
    "    X_test_scaled = scaler.transform(X_test_transformed)\n",
    "\n",
    "    # Your training and evaluation steps for this fold\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    preds = rf.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    avg.append(acc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: Accuracy score: {acc:.2f}\")\n",
    "\n",
    "print(f\"Average accuracy score : {sum(avg)/len(avg):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "avg = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_transformed = transformer.fit_transform(X_train)\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
    "    X_test_scaled = scaler.transform(X_test_transformed)\n",
    "\n",
    "    # Your training and evaluation steps for this fold\n",
    "    xgb_clsfr.fit(X_train_scaled, y_train)\n",
    "    preds = xgb_clsfr.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    avg.append(acc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: Accuracy score: {acc:.2f}\")\n",
    "\n",
    "print(f\"Average accuracy score : {sum(avg)/len(avg):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "avg = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train_transformed = transformer.fit_transform(X_train)\n",
    "    X_test_transformed = transformer.transform(X_test)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_transformed)\n",
    "    X_test_scaled = scaler.transform(X_test_transformed)\n",
    "\n",
    "    # Your training and evaluation steps for this fold\n",
    "    NN_cls.fit(X_train_scaled, y_train,epochs=150,verbose=0)\n",
    "    preds = np.argmax(NN_cls.predict(X_test_scaled),axis=1)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    avg.append(acc)\n",
    "    \n",
    "    print(f\"Fold {fold + 1}: Accuracy score: {acc:.2f}\")\n",
    "\n",
    "print(f\"Average accuracy score : {sum(avg)/len(avg):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = transformed_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlated_pairs(data, threshold):\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    # Set the correlation threshold\n",
    "    threshold = threshold  # Adjust this threshold as needed\n",
    "\n",
    "    # Find feature pairs with correlation above the threshold\n",
    "    highly_correlated_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                pair = (correlation_matrix.columns[i], correlation_matrix.columns[j], correlation_matrix.iloc[i, j])\n",
    "                highly_correlated_pairs.append(pair)\n",
    "\n",
    "    # Create a dictionary to store correlated features for each unique feature\n",
    "    correlated_features_dict = {}\n",
    "    for pair in highly_correlated_pairs:\n",
    "        if pair[0] not in correlated_features_dict:\n",
    "            correlated_features_dict[pair[0]] = [pair[1]]\n",
    "        else:\n",
    "            correlated_features_dict[pair[0]].append(pair[1])\n",
    "\n",
    "        if pair[1] not in correlated_features_dict:\n",
    "            correlated_features_dict[pair[1]] = [pair[0]]\n",
    "        else:\n",
    "            correlated_features_dict[pair[1]].append(pair[0])\n",
    "\n",
    "    # Display correlated features for each unique feature\n",
    "    for feature, correlated_features in correlated_features_dict.items():\n",
    "        print(f\"{feature} is strongly correlated to \\033[1m{len(correlated_features)}\\033[0m feature(s): {', '.join(correlated_features)}\")\n",
    "\n",
    "    return highly_correlated_pairs,correlated_features_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_correlated_pairs(transformed_df,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance & SHAP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "features_df = pd.DataFrame({'Feature': transformed_df.drop('Recurred',axis=1).columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "custom_colors = ['blue', 'green', 'red', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'brown', 'gray']\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.barh(features_df['Feature'], features_df['Importance'],color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature importances\n",
    "feature_importances = xgb_clsfr.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and importances\n",
    "features_df = pd.DataFrame({'Feature': transformed_df.drop('Recurred',axis=1).columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.barh(features_df['Feature'], features_df['Importance'],color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = transformed_df.corr()['Recurred'].abs().sort_values(ascending=False)\n",
    "\n",
    "corr.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = pd.DataFrame({'Feature': corr.index, 'Correlation with Target': corr.values})\n",
    "\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.barh(correlation_df['Feature'], correlation_df['Correlation with Target'],color=colors)\n",
    "plt.xlabel('Correlation')\n",
    "plt.title('Correlation of Features with Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feature_names))  # Length of the feature names\n",
    "print(X_test_scaled.shape[1])  # Number of features in the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "\n",
    "feature_names = transformed_df.drop('Recurred',axis=1).columns\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values[1], X_test_scaled, feature_names=feature_names,show=False, plot_size=(15, 6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_clsfr)\n",
    "\n",
    "\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "\n",
    "feature_names = transformed_df.drop('Recurred',axis=1).columns\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, show=False, plot_size=(15, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines & Model Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('estimator', rf)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(transformer,open('models/transformer.pkl','wb'))\n",
    "pickle.dump(pipe,open('models/pipe.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[0].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [27, 'F', 'No', 'No', 'No', 'Euthyroid',\n",
    "       'Single nodular goiter-left', 'No', 'Micropapillary', 'Uni-Focal',\n",
    "       'Low', 'T1a', 'N0', 'M0', 'I', 'Indeterminate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(arr,dtype=object).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(data=arr,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "column_names = X.columns.tolist()\n",
    "\n",
    "# Save column names to a JSON file\n",
    "with open('column_names.json', 'w') as json_file:\n",
    "    json.dump(column_names, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('column_names.json','r') as json_file:\n",
    "    column_names = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_1 = pickle.load(open(\"models/transformer.pkl\",\"rb\"))\n",
    "pipeline = pickle.load(open(\"models/pipe.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = transformer_1.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
